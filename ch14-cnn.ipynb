{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CNN use fewer parameters and thus reduce overfitting.  \n",
    "* CNN can detect the connection in spatial dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this case, there are (3 x 3 x 3 + 1) x 100 + (3 x 3 x 100 + 1) x 200 + (3 x 3 x 200 + 1) x 400 = 9,034,00 parameters.     \n",
    "* Let's see the image size first. \n",
    "    * Input contain 200 x 300 pixels  \n",
    "    * Layer 1 contain (200)/2 + 1 x (300)/2 = 100 x 150 pixels\n",
    "        * The number of float32 is 100 x 150 x 100 x 4 Bytes = 6 MB\n",
    "    * Layer 2 contain (100)/2 x (150)/2 = 50 x 75 pixels\n",
    "        * The number of float32 is 50 x 75 x 200 x 4 Bytes = 3 MB \n",
    "    * Layer 3 contain (50)/2 x (75)/2 = 25 x 38 pixels\n",
    "        * The number of float32 is 25 x 38 x 400 x 4 Bytes = 1.52 MB\n",
    "    * Total for one instance is 6 + 3 + 1.52 = 10.52 MB\n",
    "* Note that we need all of the computing value of all the layer at training state since it is needed for backpropagation. So, the minimum memory require is 10.52 MB + input image memory (0.7 MB) (we will ignore the backpropagation memory since it can also be release after the calculation is pass through that layer).\n",
    "* We need 11.22 MB * 50 = 561 MB for 50 mini-batch.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try reducing the size of CNN by increasing the stride.  \n",
    "* Run CNN on multiple computers.  \n",
    "* Reduce mini-batch size.  \n",
    "* Reduce tf.float32 to tf.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Max pooling layer is faster to compute and it has no parameter to train.  \n",
    "* It can, also, compress the graph while preserve the information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When you suspect that there are some feature map that exhibit strongly feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alexnet introduce the Local Response Normalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The idea of FCN is to replace the dense layer with convolutional layer. The number of filter in this cnn have to be equal to number of neuron in the dense layer.  \n",
    "    * In fact, the computation of such dense layer and cnn is the same.  \n",
    "    * The only difference is that the FCN can implement to any size of images (but the number of channels have to be the same). \n",
    "    * This is the foundation of YOLO model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the deeper layer of CNN, the size of the images is compressed. So, it hard to classify image based on original image pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tfds.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "uint8\n",
      "0\n",
      "255\n",
      "(60000,)\n",
      "uint8\n",
      "0\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train.dtype)\n",
    "print(x_train.min())\n",
    "print(x_train.max())\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train.dtype)\n",
    "print(y_train.min())\n",
    "print(y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scale = x_train/255.\n",
    "x_test_scale = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic CNN model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpandDimsLayer(keras.layers.Layer):\n",
    "    def __init__(self, dtype = tf.float32, *args, **kwargs):\n",
    "        super().__init__(dtype = dtype, *args, **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.expand_dims(inputs, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([28 28], shape=(2,), dtype=int32)\n",
      "tf.Tensor([28 28  1], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "expand_dims = ExpandDimsLayer()\n",
    "temp = tf.constant([1])\n",
    "print(tf.shape(x_train[0]))\n",
    "print(tf.shape(expand_dims(x_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = tf.data.Dataset.from_tensor_slices(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([28 28], shape=(2,), dtype=int32)\n",
      "tf.Tensor([28 28  1], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for data in trainset.take(1):\n",
    "    print(tf.shape(data))\n",
    "    print(tf.shape(expand_dims(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape = [28, 28]),\n",
    "    ExpandDimsLayer(),\n",
    "    keras.layers.Conv2D(32, 3, activation = 'elu'),\n",
    "    keras.layers.Conv2D(32, 3, activation = 'elu'),\n",
    "    keras.layers.MaxPool2D(),\n",
    "    keras.layers.Conv2D(64, 3, activation = 'elu'),\n",
    "    keras.layers.Conv2D(64, 3, activation = 'elu'),\n",
    "    keras.layers.MaxPool2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation = 'elu'),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', metrics=['accuracy'], optimizer = keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "expand_dims_layer (ExpandDim (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 168,502\n",
      "Trainable params: 168,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 171s 91ms/step - loss: 0.1158 - accuracy: 0.9640 - val_loss: 0.0808 - val_accuracy: 0.9763\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 201s 107ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 0.0448 - val_accuracy: 0.9857\n",
      "Epoch 3/20\n",
      " 661/1875 [=========>....................] - ETA: 2:14 - loss: 0.0342 - accuracy: 0.9890"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5bcdd1862d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(x_train_scale, y_train, epochs = 20, batch_size = 32, \n\u001b[0;32m----> 2\u001b[0;31m           validation_data=(x_test_scale, y_test), validation_batch_size=32)\n\u001b[0m",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train_scale, y_train, epochs = 20, batch_size = 32, \n",
    "          validation_data=(x_test_scale, y_test), validation_batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "base_model2 = keras.applications.ResNet50(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, None, None, 3 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, None, None, 6 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, None, None, 6 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, None, None, 6 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, None, None, 6 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, None, None, 6 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, None, None, 6 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, None, None, 6 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, None, None, 6 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, None, None, 6 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, None, None, 6 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, None, None, 2 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, None, None, 2 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, None, None, 2 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, None, None, 6 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, None, None, 6 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, None, None, 6 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, None, None, 6 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, None, None, 2 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, None, None, 2 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, None, None, 6 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, None, None, 6 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, None, None, 6 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, None, None, 6 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, None, None, 6 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, None, None, 6 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, None, None, 2 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, None, None, 2 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, None, None, 2 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, None, None, 2 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, None, None, 1 32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, None, None, 1 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, None, None, 1 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, None, None, 1 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, None, None, 1 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, None, None, 5 131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, None, None, 5 0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, None, None, 5 0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, None, None, 1 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, None, None, 1 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, None, None, 1 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, None, None, 1 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, None, None, 5 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, None, None, 5 0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, None, None, 1 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, None, None, 1 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, None, None, 1 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, None, None, 1 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, None, None, 5 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, None, None, 5 0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, None, None, 1 65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, None, None, 1 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, None, None, 1 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, None, None, 1 147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, None, None, 1 512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, None, None, 1 0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, None, None, 5 66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, None, None, 5 2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, None, None, 5 0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rescale layer to transform the image to the appropriate size of resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.image import grayscale_to_rgb\n",
    "from tensorflow.image import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = grayscale_to_rgb(expand_dims(tf.constant(x_train[0])))\n",
    "rgb_img_resize = tf.cast(resize(rgb_img, size=(224, 224)), dtype=tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(253, shape=(), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(rgb_img_resize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb94cf0a690>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(rgb_img_resize)\n",
    "# plt.show()\n",
    "# plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessImageLayer(keras.layers.Layer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(self, *args, **kwargs)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        inputs = expand_dims(inputs)\n",
    "        inputs = grayscale_to_rgb(inputs)\n",
    "        inputs = tf.cast(resize(inputs, size=(224, 224)), dtype = tf.float32)\n",
    "        return inputs/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = PreprocessImageLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create new model to transform image\n",
    "keras.backend.clear_session()\n",
    "\n",
    "inputs = keras.layers.Input(shape = [28, 28])\n",
    "outputs = PreprocessImageLayer()(inputs)\n",
    "outputs = base_model2(outputs)\n",
    "\n",
    "my_model_a1 = keras.layers.GlobalAveragePooling2D()(outputs)\n",
    "my_model_a2 = keras.layers.Dropout(0.25)(my_model_a1)\n",
    "outputs = keras.layers.Dense(10, activation = 'softmax')(my_model_a2)\n",
    "\n",
    "my_model = keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "for layer in base_model2.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "my_model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "preprocess_image_layer (Prep (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, None, None, 2048)  23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  19/1875 [..............................] - ETA: 1:51:02 - loss: 2.4505 - accuracy: 0.1053"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-3c37bef60582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Documents/practice-handson-ml2/practice_handson_ml_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_model.fit(x_train, y_train, epochs = 2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training takes too long but it may be better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
